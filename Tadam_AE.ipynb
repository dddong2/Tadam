{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390b9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# model\n",
    "class CAE(tf.keras.Model):\n",
    "    def __init__(self, in_shape, filters, code_dim):\n",
    "        super(CAE, self).__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.filters = filters\n",
    "        self.code_dim = code_dim\n",
    "        \n",
    "        # input\n",
    "        self.inputs = tf.keras.layers.Input(shape=self.in_shape)\n",
    "\n",
    "        # encoder\n",
    "        self.enc01 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[0], kernel_size=3, strides=2, padding='same')(self.inputs)\n",
    "        self.enc01 = tf.keras.activations.swish(self.enc01)\n",
    "        \n",
    "        self.enc02 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[1], kernel_size=3, strides=2, padding='same')(self.enc01)\n",
    "        self.enc02 = tf.keras.activations.swish(self.enc02)\n",
    "        \n",
    "        self.enc03 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[2], kernel_size=3, strides=2, padding='same')(self.enc02)\n",
    "        self.enc03 = tf.keras.activations.swish(self.enc03)\n",
    "        self.enc03_flat = tf.keras.layers.Flatten()(self.enc03)\n",
    "        \n",
    "        # code\n",
    "        self.code = tf.keras.layers.Dense(self.code_dim)(self.enc03_flat)\n",
    "        \n",
    "        # decoder\n",
    "        self.dec03 = tf.keras.layers.Dense(self.enc03_flat.shape[-1])(self.code)\n",
    "        self.dec03 = tf.keras.activations.swish(self.dec03)\n",
    "        self.dec03 = tf.keras.layers.Reshape(target_shape=self.enc03.shape[1:])(self.dec03)\n",
    "\n",
    "        self.dec02 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.filters[1], kernel_size=3, strides=2, padding='same')(self.dec03)\n",
    "        self.dec02 = tf.keras.activations.swish(self.dec02)\n",
    "\n",
    "        self.dec01 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.filters[0], kernel_size=3, strides=2, padding='same')(self.dec02)\n",
    "        self.dec01 = tf.keras.activations.swish(self.dec01)\n",
    "        \n",
    "        # output\n",
    "        self.outputs = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.in_shape[2], kernel_size=3, strides=2, padding='same')(self.dec01)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=self.inputs, outputs=self.outputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1977557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_data(data_name, batch_size):\n",
    "    if data_name == 'MNIST':\n",
    "        (train_ds,_), (test_ds,_) = tf.keras.datasets.mnist.load_data()\n",
    "    elif data_name == 'Fashion-MNIST':\n",
    "        (train_ds,_), (test_ds,_) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    elif data_name == 'CIFAR-10':\n",
    "        (train_ds,_), (test_ds,_) = tf.keras.datasets.cifar10.load_data()\n",
    "    \n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_size = train_ds.shape[0]\n",
    "    test_size = test_ds.shape[0]\n",
    "\n",
    "    train_ds = preprocess_images(data_name, train_ds)\n",
    "    test_ds = preprocess_images(data_name, test_ds)\n",
    "\n",
    "    train_ds = (tf.data.Dataset.from_tensor_slices(train_ds)\n",
    "                     .shuffle(train_size).batch(batch_size))\n",
    "    test_ds = (tf.data.Dataset.from_tensor_slices(test_ds)\n",
    "                    .shuffle(test_size).batch(batch_size))\n",
    "\n",
    "    return train_ds, test_ds, train_size\n",
    "\n",
    "\n",
    "def preprocess_images(data_name, img):\n",
    "    if data_name == 'MNIST':\n",
    "        img = (img.reshape((img.shape[0], 28, 28, 1)) / 255.).astype('float32')\n",
    "        img = tf.image.resize(img, [32,32])\n",
    "    if data_name == 'Fashion-MNIST':\n",
    "        img = (img.reshape((img.shape[0], 28, 28, 1)) / 255.).astype('float32')\n",
    "        img = tf.image.resize(img, [32,32])\n",
    "    elif data_name == 'CIFAR-10':\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc830f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient flatten\n",
    "def flatgrad(grad_list):\n",
    "    \"\"\"\n",
    "    flattens gradients.\n",
    "\n",
    "    :param grad_list: ([TensorFlow Tensor]) the gradients\n",
    "    :return: ([TensorFlow Tensor]) flattened gradient\n",
    "    \"\"\"\n",
    "    return tf.concat(axis=0, values=[tf.reshape(grad, [-1]) for grad in grad_list])\n",
    "\n",
    "\n",
    "def flat_to_grad_list(flat, var_list):\n",
    "    \"\"\"\n",
    "    converts flats to the form of var_list.\n",
    "    :param flat:\n",
    "    :param var_list:\n",
    "    :return: [(Tensorflow Tensor)]\n",
    "    \"\"\"\n",
    "    splits = tf.split(flat, [numel(w) for w in var_list])\n",
    "    return [tf.reshape(t, var_shape(w)) for t, w in zip(splits, var_list)]\n",
    "\n",
    "\n",
    "def var_shape(tensor):\n",
    "    \"\"\"\n",
    "    get TensorFlow Tensor shape\n",
    "    :param tensor: (TensorFlow Tensor) the input tensor\n",
    "    :return: ([int]) the shape\n",
    "    \"\"\"\n",
    "    out = tensor.get_shape().as_list()\n",
    "    assert all(isinstance(a, int) for a in out), \\\n",
    "        \"shape function assumes that shape is fully known\"\n",
    "    return out\n",
    "\n",
    "\n",
    "def numel(tensor):\n",
    "    \"\"\"\n",
    "    get TensorFlow Tensor's number of elements\n",
    "    :param tensor: (TensorFlow Tensor) the input tensor\n",
    "    :return: (int) the number of elements\n",
    "    \"\"\"\n",
    "    return int(np.prod(var_shape(tensor)))\n",
    "\n",
    "\n",
    "# loss computation\n",
    "def compute_mse(train_model, x, training=True):\n",
    "    x_logit = train_model(x, training=training)\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    loss = loss_fn(x, x_logit)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd796d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TADAM\n",
    "@tf.function\n",
    "def train_step(model, opt, x, lr, beta1, beta2, gamma, ls_h, ls, pr, dt, m_h, m, s, v, t, total_steps, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Executes one training step and returns the loss.\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_mse(model,x, True)\n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    g_flat = flatgrad(gradient)\n",
    "\n",
    "    # bias correction\n",
    "    bp1 = tf.pow(beta1, t)\n",
    "    bp2 = tf.pow(beta2, t)\n",
    "    bc1 = 1.0 - bp1\n",
    "    bc2 = 1.0 - bp2\n",
    "\n",
    "    # compute delta\n",
    "    if t>1:\n",
    "        rho = (ls_h - loss) / tf.maximum(pr, eps)\n",
    "        dt_min = tf.pow(1.- gamma, (t-1) / total_steps)\n",
    "        dt_max = 1. + tf.pow(gamma, (t-1) / total_steps)\n",
    "        f1 = lambda: dt_min\n",
    "        f2 = lambda: dt_max\n",
    "        f3 = lambda: 1.0\n",
    "        r = tf.case([(tf.less(rho, gamma), f1), (tf.greater(rho, 1. - gamma), f2)], default=f3, exclusive=True)\n",
    "        dt = tf.minimum(tf.maximum(r * dt, dt_min), dt_max)\n",
    "    else:\n",
    "        dt = 1.0\n",
    "\n",
    "    # moving varience\n",
    "    dv = tf.square(g_flat - m_h) * (beta2 - bp2) / bc2 \n",
    "    v = beta2 * v + (1.0 - beta2) * dv\n",
    "    v_h = v / bc2\n",
    "\n",
    "    # first moment\n",
    "    m = beta1 * m + (1.0 - beta1) * g_flat\n",
    "    m_h = m / bc1\n",
    "\n",
    "    # second moment\n",
    "    s = beta2 * s + (1.0 - beta2) * tf.square(g_flat)\n",
    "    s_h = s / bc2\n",
    "\n",
    "    # fisher vector\n",
    "    f_h = (1.0 + tf.reduce_sum(tf.square(m_h) / (v_h + eps))) * v_h\n",
    "\n",
    "    # apply trust region\n",
    "    u_h = tf.maximum(dt * f_h, tf.sqrt(s_h))\n",
    "    g_h = m_h * dt / (u_h + eps)\n",
    "\n",
    "    # update\n",
    "    g_update = flat_to_grad_list(g_h, model.trainable_variables)\n",
    "    grads_and_vars = [(grad, var) for grad, var in zip(g_update, model.trainable_variables)]\n",
    "    opt.apply_gradients(grads_and_vars)\n",
    "\n",
    "    # moving avg of loss\n",
    "    ls = beta1 * ls + (1.0 - beta1) * loss\n",
    "    ls_h = ls / bc1\n",
    "\n",
    "    # predict reduction\n",
    "    pr1 = tf.reduce_sum(m_h * g_h) \n",
    "    pr2 = tf.square(pr1) + tf.reduce_sum(v_h * tf.square(g_h))\n",
    "    pr = (pr1 - 0.5 * pr2) * lr\n",
    "\n",
    "    return ls_h, ls, loss, pr, dt, m_h, m, s, v, t + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5925c4d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def training(data_name, in_shape, filters, code_dim, batch_size=128, epochs=1, \n",
    "             init_lr=1e-3, beta1=0.9, beta2=0.999, gamma=0.25, eps=1e-8, seed=0):\n",
    "    \n",
    "    print('DATA: {}, BATCH: {}, EPOCH: {}'\n",
    "          .format(data_name, batch_size, epochs))\n",
    "    print('INIT_LR: {:.0e}, BETA1: {:.4f}, BETA2: {:.4f}, GAMMA: {:.4f}'\n",
    "          .format(init_lr, beta1, beta2, gamma))\n",
    "    \n",
    "    # fix seed\n",
    "    tf.random.set_seed(seed)  # Tensorflow\n",
    "    np.random.seed(seed)  # numpy\n",
    "    random.seed(seed)  # Python\n",
    "     \n",
    "    # set model\n",
    "    model = CAE(in_shape, filters, code_dim).model\n",
    "    model.summary()\n",
    "    \n",
    "    # load data\n",
    "    train_dataset, test_dataset, train_size = load_data(data_name, batch_size)\n",
    "    steps_per_epoch = int(train_size / batch_size)\n",
    "    total_steps = int(steps_per_epoch * epochs)\n",
    "    \n",
    "    # SGD\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=init_lr)\n",
    "    \n",
    "    # initial parameters\n",
    "    ls_h = 0.0\n",
    "    ls = 0.0\n",
    "    pr = 0.0\n",
    "    m_h = 0.0\n",
    "    m = 0.0\n",
    "    s = 0.0\n",
    "    v = eps\n",
    "    dt = 1.0\n",
    "    t = 1.0\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(1, epochs + 1):        \n",
    "        tmloss = tf.keras.metrics.Mean()\n",
    "        start_time = time.time()\n",
    "        for train_x in train_dataset:\n",
    "            ls_h, ls, loss, pr, dt, m_h, m, s, v, t = train_step(model, opt, train_x, \n",
    "                init_lr, beta1, beta2, gamma, ls_h, ls, pr, dt, m_h, m, s, v, t, total_steps)\n",
    "            tmloss(loss)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "        tloss = tmloss.result()\n",
    "\n",
    "        vmloss = tf.keras.metrics.Mean()\n",
    "        for test_x in test_dataset:\n",
    "            loss = compute_mse(model, test_x, False)\n",
    "            vmloss(loss) \n",
    "        vloss = vmloss.result()\n",
    "        \n",
    "        print('Epoch: {}, loss_t: {:.4e}, loss_v: {:.4e}, dt: {:.2f}, time: {:.2f}'\n",
    "              .format(epoch, tloss, vloss, dt, train_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f48ffa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: MNIST, BATCH: 128, EPOCH: 100\n",
      "INIT_LR: 1e-03, BETA1: 0.9000, BETA2: 0.9990, GAMMA: 0.2500\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 16)        160       \n",
      "                                                                 \n",
      " tf.nn.silu (TFOpLambda)     (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 32)          4640      \n",
      "                                                                 \n",
      " tf.nn.silu_1 (TFOpLambda)   (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " tf.nn.silu_2 (TFOpLambda)   (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                16400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              17408     \n",
      "                                                                 \n",
      " tf.nn.silu_3 (TFOpLambda)   (None, 1024)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 32)         18464     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " tf.nn.silu_4 (TFOpLambda)   (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 16)       4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " tf.nn.silu_5 (TFOpLambda)   (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 1)        145       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,337\n",
      "Trainable params: 80,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },

    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss_t: 3.0960e-02, loss_v: 8.5160e-03, dt: 1.98, time: 8.45\n",
      "Epoch: 2, loss_t: 7.5089e-03, loss_v: 6.6965e-03, dt: 1.97, time: 4.09\n",
      "Epoch: 3, loss_t: 6.3080e-03, loss_v: 5.8726e-03, dt: 1.93, time: 4.16\n",
      "Epoch: 4, loss_t: 5.7805e-03, loss_v: 5.6572e-03, dt: 1.88, time: 4.06\n",
      "Epoch: 5, loss_t: 5.4316e-03, loss_v: 5.2908e-03, dt: 1.93, time: 4.20\n",
      "Epoch: 6, loss_t: 5.1926e-03, loss_v: 5.0891e-03, dt: 1.92, time: 4.13\n",
      "Epoch: 7, loss_t: 5.0272e-03, loss_v: 4.9590e-03, dt: 1.87, time: 4.10\n",
      "Epoch: 8, loss_t: 4.8847e-03, loss_v: 4.8127e-03, dt: 1.77, time: 4.14\n",
      "Epoch: 9, loss_t: 4.7653e-03, loss_v: 4.7324e-03, dt: 1.83, time: 4.21\n",
      "Epoch: 10, loss_t: 4.6741e-03, loss_v: 4.6151e-03, dt: 1.77, time: 4.08\n",
      "Epoch: 11, loss_t: 4.5990e-03, loss_v: 4.5685e-03, dt: 1.74, time: 4.15\n",
      "Epoch: 12, loss_t: 4.5281e-03, loss_v: 4.5227e-03, dt: 1.78, time: 4.14\n",
      "Epoch: 13, loss_t: 4.4550e-03, loss_v: 4.4895e-03, dt: 1.83, time: 4.07\n",
      "Epoch: 14, loss_t: 4.4084e-03, loss_v: 4.4145e-03, dt: 1.75, time: 4.07\n",
      "Epoch: 15, loss_t: 4.3669e-03, loss_v: 4.3937e-03, dt: 1.59, time: 4.12\n",
      "Epoch: 16, loss_t: 4.3161e-03, loss_v: 4.3009e-03, dt: 1.80, time: 4.11\n",
      "Epoch: 17, loss_t: 4.2699e-03, loss_v: 4.3185e-03, dt: 1.70, time: 4.11\n",
      "Epoch: 18, loss_t: 4.2414e-03, loss_v: 4.2961e-03, dt: 1.60, time: 4.11\n",
      "Epoch: 19, loss_t: 4.2125e-03, loss_v: 4.2593e-03, dt: 1.77, time: 4.04\n",
      "Epoch: 20, loss_t: 4.1717e-03, loss_v: 4.2303e-03, dt: 1.76, time: 4.04\n",
      "Epoch: 21, loss_t: 4.1475e-03, loss_v: 4.2438e-03, dt: 1.55, time: 4.19\n",
      "Epoch: 22, loss_t: 4.1299e-03, loss_v: 4.2025e-03, dt: 1.53, time: 4.04\n",
      "Epoch: 23, loss_t: 4.0968e-03, loss_v: 4.2259e-03, dt: 1.73, time: 4.20\n",
      "Epoch: 24, loss_t: 4.0748e-03, loss_v: 4.1271e-03, dt: 1.60, time: 4.21\n",
      "Epoch: 25, loss_t: 4.0594e-03, loss_v: 4.1468e-03, dt: 1.48, time: 4.15\n",
      "Epoch: 26, loss_t: 4.0304e-03, loss_v: 4.1672e-03, dt: 1.70, time: 4.11\n",
      "Epoch: 27, loss_t: 4.0172e-03, loss_v: 4.0807e-03, dt: 1.34, time: 4.30\n",
      "Epoch: 28, loss_t: 4.0025e-03, loss_v: 4.0610e-03, dt: 1.55, time: 4.12\n",
      "Epoch: 29, loss_t: 3.9794e-03, loss_v: 4.1292e-03, dt: 1.67, time: 4.09\n",
      "Epoch: 30, loss_t: 3.9597e-03, loss_v: 4.0639e-03, dt: 1.66, time: 4.14\n",
      "Epoch: 31, loss_t: 3.9484e-03, loss_v: 4.0583e-03, dt: 1.65, time: 4.10\n",
      "Epoch: 32, loss_t: 3.9362e-03, loss_v: 4.0196e-03, dt: 1.36, time: 4.13\n",
      "Epoch: 33, loss_t: 3.9216e-03, loss_v: 4.0470e-03, dt: 1.63, time: 4.23\n",
      "Epoch: 34, loss_t: 3.9075e-03, loss_v: 4.0415e-03, dt: 1.62, time: 4.11\n",
      "Epoch: 35, loss_t: 3.8909e-03, loss_v: 3.9647e-03, dt: 1.61, time: 4.11\n",
      "Epoch: 36, loss_t: 3.8849e-03, loss_v: 4.0156e-03, dt: 1.18, time: 4.10\n",
      "Epoch: 37, loss_t: 3.8703e-03, loss_v: 3.9332e-03, dt: 1.60, time: 4.16\n",
      "Epoch: 38, loss_t: 3.8489e-03, loss_v: 3.9661e-03, dt: 1.42, time: 4.10\n",
      "Epoch: 39, loss_t: 3.8457e-03, loss_v: 3.9611e-03, dt: 1.58, time: 4.15\n",
      "Epoch: 40, loss_t: 3.8302e-03, loss_v: 3.9291e-03, dt: 0.89, time: 4.09\n",
      "Epoch: 41, loss_t: 3.8134e-03, loss_v: 3.9313e-03, dt: 1.57, time: 4.07\n",
      "Epoch: 42, loss_t: 3.8098e-03, loss_v: 3.9227e-03, dt: 1.56, time: 4.18\n",
      "Epoch: 43, loss_t: 3.7996e-03, loss_v: 3.9137e-03, dt: 1.37, time: 4.19\n",
      "Epoch: 44, loss_t: 3.7852e-03, loss_v: 3.9672e-03, dt: 1.36, time: 4.21\n",
      "Epoch: 45, loss_t: 3.7769e-03, loss_v: 3.9092e-03, dt: 1.54, time: 4.16\n",
      "Epoch: 46, loss_t: 3.7631e-03, loss_v: 3.9274e-03, dt: 1.34, time: 4.20\n",
      "Epoch: 47, loss_t: 3.7612e-03, loss_v: 3.8845e-03, dt: 1.52, time: 4.13\n",
      "Epoch: 48, loss_t: 3.7502e-03, loss_v: 3.8659e-03, dt: 1.32, time: 4.13\n",
      "Epoch: 49, loss_t: 3.7523e-03, loss_v: 3.8778e-03, dt: 1.14, time: 4.09\n",
      "Epoch: 50, loss_t: 3.7273e-03, loss_v: 3.8726e-03, dt: 1.50, time: 4.13\n",
      "Epoch: 51, loss_t: 3.7250e-03, loss_v: 3.8946e-03, dt: 1.49, time: 4.17\n",
      "Epoch: 52, loss_t: 3.7198e-03, loss_v: 3.8172e-03, dt: 1.10, time: 4.24\n",
      "Epoch: 53, loss_t: 3.7092e-03, loss_v: 3.8777e-03, dt: 1.27, time: 4.26\n",
      "Epoch: 54, loss_t: 3.6998e-03, loss_v: 3.8720e-03, dt: 1.47, time: 4.13\n",
      "Epoch: 55, loss_t: 3.6958e-03, loss_v: 3.8626e-03, dt: 1.47, time: 4.24\n",
      "Epoch: 56, loss_t: 3.6906e-03, loss_v: 3.8403e-03, dt: 1.24, time: 4.12\n",
      "Epoch: 57, loss_t: 3.6864e-03, loss_v: 3.8093e-03, dt: 1.23, time: 4.18\n",
      "Epoch: 58, loss_t: 3.6727e-03, loss_v: 3.8881e-03, dt: 1.45, time: 4.18\n",
      "Epoch: 59, loss_t: 3.6666e-03, loss_v: 3.7737e-03, dt: 1.22, time: 4.09\n",
      "Epoch: 60, loss_t: 3.6666e-03, loss_v: 3.8421e-03, dt: 1.02, time: 4.07\n",
      "Epoch: 61, loss_t: 3.6542e-03, loss_v: 3.8161e-03, dt: 1.43, time: 4.10\n",
      "Epoch: 62, loss_t: 3.6460e-03, loss_v: 3.8046e-03, dt: 0.84, time: 3.98\n",
      "Epoch: 63, loss_t: 3.6494e-03, loss_v: 3.8059e-03, dt: 1.42, time: 4.14\n",
      "Epoch: 64, loss_t: 3.6407e-03, loss_v: 3.7831e-03, dt: 1.17, time: 4.14\n",
      "Epoch: 65, loss_t: 3.6319e-03, loss_v: 3.8851e-03, dt: 1.41, time: 4.18\n",
      "Epoch: 66, loss_t: 3.6262e-03, loss_v: 3.7895e-03, dt: 1.11, time: 4.13\n",
      "Epoch: 67, loss_t: 3.6276e-03, loss_v: 3.7969e-03, dt: 1.39, time: 4.07\n",
      "Epoch: 68, loss_t: 3.6172e-03, loss_v: 3.8264e-03, dt: 0.94, time: 4.18\n",
      "Epoch: 69, loss_t: 3.6068e-03, loss_v: 3.7706e-03, dt: 1.29, time: 4.00\n",
      "Epoch: 70, loss_t: 3.5995e-03, loss_v: 3.7637e-03, dt: 1.38, time: 4.10\n",
      "Epoch: 71, loss_t: 3.5977e-03, loss_v: 3.7893e-03, dt: 1.25, time: 4.23\n",
      "Epoch: 72, loss_t: 3.5961e-03, loss_v: 3.7567e-03, dt: 0.81, time: 4.10\n",
      "Epoch: 73, loss_t: 3.5889e-03, loss_v: 3.7525e-03, dt: 1.10, time: 4.17\n",
      "Epoch: 74, loss_t: 3.5828e-03, loss_v: 3.7717e-03, dt: 1.36, time: 4.12\n",
      "Epoch: 75, loss_t: 3.5767e-03, loss_v: 3.7834e-03, dt: 1.29, time: 4.06\n",
      "Epoch: 76, loss_t: 3.5734e-03, loss_v: 3.7686e-03, dt: 0.80, time: 4.06\n",
      "Epoch: 77, loss_t: 3.5718e-03, loss_v: 3.7870e-03, dt: 1.34, time: 4.21\n",
      "Epoch: 78, loss_t: 3.5712e-03, loss_v: 3.7476e-03, dt: 1.07, time: 4.11\n",
      "Epoch: 79, loss_t: 3.5647e-03, loss_v: 3.7312e-03, dt: 0.85, time: 4.17\n",
      "Epoch: 80, loss_t: 3.5544e-03, loss_v: 3.7598e-03, dt: 1.11, time: 4.18\n",
      "Epoch: 81, loss_t: 3.5553e-03, loss_v: 3.7414e-03, dt: 1.32, time: 4.17\n",
      "Epoch: 82, loss_t: 3.5484e-03, loss_v: 3.7321e-03, dt: 0.79, time: 4.01\n",
      "Epoch: 83, loss_t: 3.5461e-03, loss_v: 3.7118e-03, dt: 1.32, time: 4.17\n",
      "Epoch: 84, loss_t: 3.5388e-03, loss_v: 3.7451e-03, dt: 1.03, time: 4.08\n",
      "Epoch: 85, loss_t: 3.5408e-03, loss_v: 3.7395e-03, dt: 1.31, time: 4.17\n",
      "Epoch: 86, loss_t: 3.5446e-03, loss_v: 3.7232e-03, dt: 1.30, time: 4.11\n",
      "Epoch: 87, loss_t: 3.5340e-03, loss_v: 3.6999e-03, dt: 0.79, time: 4.12\n",
      "Epoch: 88, loss_t: 3.5179e-03, loss_v: 3.7309e-03, dt: 1.29, time: 4.12\n",
      "Epoch: 89, loss_t: 3.5228e-03, loss_v: 3.7176e-03, dt: 1.00, time: 4.17\n",
      "Epoch: 90, loss_t: 3.5156e-03, loss_v: 3.7209e-03, dt: 1.28, time: 4.25\n",
      "Epoch: 91, loss_t: 3.5176e-03, loss_v: 3.6844e-03, dt: 0.77, time: 4.09\n",
      "Epoch: 92, loss_t: 3.5089e-03, loss_v: 3.7872e-03, dt: 1.28, time: 4.16\n",
      "Epoch: 93, loss_t: 3.5105e-03, loss_v: 3.6988e-03, dt: 0.76, time: 4.15\n",
      "Epoch: 94, loss_t: 3.5027e-03, loss_v: 3.7346e-03, dt: 1.23, time: 4.12\n",
      "Epoch: 95, loss_t: 3.5023e-03, loss_v: 3.7234e-03, dt: 0.93, time: 4.17\n",
      "Epoch: 96, loss_t: 3.4925e-03, loss_v: 3.7435e-03, dt: 1.21, time: 4.17\n",
      "Epoch: 97, loss_t: 3.5006e-03, loss_v: 3.6899e-03, dt: 0.91, time: 4.09\n",
      "Epoch: 98, loss_t: 3.4914e-03, loss_v: 3.6538e-03, dt: 0.75, time: 4.17\n",
      "Epoch: 99, loss_t: 3.4888e-03, loss_v: 3.6842e-03, dt: 1.18, time: 4.17\n",
      "Epoch: 100, loss_t: 3.4867e-03, loss_v: 3.6857e-03, dt: 0.94, time: 4.12\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "datas = ['MNIST', 'Fashion-MNIST', 'CIFAR-10']\n",
    "in_shape = (32, 32, 1)\n",
    "filters = [16, 32, 64]\n",
    "code_dim = 16\n",
    "\n",
    "training(datas[0], in_shape, filters, code_dim, batch_size=128, epochs=100, \n",
    "         init_lr=1e-3, beta1=0.9, beta2=0.999, gamma=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2ce0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
