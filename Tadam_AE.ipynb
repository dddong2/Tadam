{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390b9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# model\n",
    "class CAE(tf.keras.Model):\n",
    "    def __init__(self, in_shape, filters, code_dim):\n",
    "        super(CAE, self).__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.filters = filters\n",
    "        self.code_dim = code_dim\n",
    "        \n",
    "        # input\n",
    "        self.inputs = tf.keras.layers.Input(shape=self.in_shape)\n",
    "\n",
    "        # encoder\n",
    "        self.enc01 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[0], kernel_size=3, strides=2, padding='same')(self.inputs)\n",
    "        self.enc01 = tf.keras.activations.swish(self.enc01)\n",
    "        \n",
    "        self.enc02 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[1], kernel_size=3, strides=2, padding='same')(self.enc01)\n",
    "        self.enc02 = tf.keras.activations.swish(self.enc02)\n",
    "        \n",
    "        self.enc03 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[2], kernel_size=3, strides=2, padding='same')(self.enc02)\n",
    "        self.enc03 = tf.keras.activations.swish(self.enc03)\n",
    "        self.enc03_flat = tf.keras.layers.Flatten()(self.enc03)\n",
    "        \n",
    "        # code\n",
    "        self.code = tf.keras.layers.Dense(self.code_dim)(self.enc03_flat)\n",
    "        \n",
    "        # decoder\n",
    "        self.dec03 = tf.keras.layers.Dense(self.enc03_flat.shape[-1])(self.code)\n",
    "        self.dec03 = tf.keras.activations.swish(self.dec03)\n",
    "        self.dec03 = tf.keras.layers.Reshape(target_shape=self.enc03.shape[1:])(self.dec03)\n",
    "\n",
    "        self.dec02 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.filters[1], kernel_size=3, strides=2, padding='same')(self.dec03)\n",
    "        self.dec02 = tf.keras.activations.swish(self.dec02)\n",
    "\n",
    "        self.dec01 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.filters[0], kernel_size=3, strides=2, padding='same')(self.dec02)\n",
    "        self.dec01 = tf.keras.activations.swish(self.dec01)\n",
    "        \n",
    "        # output\n",
    "        self.outputs = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.in_shape[2], kernel_size=3, strides=2, padding='same')(self.dec01)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=self.inputs, outputs=self.outputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1977557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_data(data_name, batch_size):\n",
    "    if data_name == 'MNIST':\n",
    "        (train_ds,_), (test_ds,_) = tf.keras.datasets.mnist.load_data()\n",
    "    elif data_name == 'Fashion-MNIST':\n",
    "        (train_ds,_), (test_ds,_) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    elif data_name == 'CIFAR-10':\n",
    "        (train_ds,_), (test_ds,_) = tf.keras.datasets.cifar10.load_data()\n",
    "    \n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_size = train_ds.shape[0]\n",
    "    test_size = test_ds.shape[0]\n",
    "\n",
    "    train_ds = preprocess_images(data_name, train_ds)\n",
    "    test_ds = preprocess_images(data_name, test_ds)\n",
    "\n",
    "    train_ds = (tf.data.Dataset.from_tensor_slices(train_ds)\n",
    "                     .shuffle(train_size).batch(batch_size))\n",
    "    test_ds = (tf.data.Dataset.from_tensor_slices(test_ds)\n",
    "                    .shuffle(test_size).batch(batch_size))\n",
    "\n",
    "    return train_ds, test_ds, train_size\n",
    "\n",
    "\n",
    "def preprocess_images(data_name, img):\n",
    "    if data_name == 'MNIST':\n",
    "        img = (img.reshape((img.shape[0], 28, 28, 1)) / 255.).astype('float32')\n",
    "        img = tf.image.resize(img, [32,32])\n",
    "    if data_name == 'Fashion-MNIST':\n",
    "        img = (img.reshape((img.shape[0], 28, 28, 1)) / 255.).astype('float32')\n",
    "        img = tf.image.resize(img, [32,32])\n",
    "    elif data_name == 'CIFAR-10':\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc830f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient flatten\n",
    "def flatgrad(grad_list):\n",
    "    \"\"\"\n",
    "    flattens gradients.\n",
    "\n",
    "    :param grad_list: ([TensorFlow Tensor]) the gradients\n",
    "    :return: ([TensorFlow Tensor]) flattened gradient\n",
    "    \"\"\"\n",
    "    return tf.concat(axis=0, values=[tf.reshape(grad, [-1]) for grad in grad_list])\n",
    "\n",
    "\n",
    "def flat_to_grad_list(flat, var_list):\n",
    "    \"\"\"\n",
    "    converts flats to the form of var_list.\n",
    "    :param flat:\n",
    "    :param var_list:\n",
    "    :return: [(Tensorflow Tensor)]\n",
    "    \"\"\"\n",
    "    splits = tf.split(flat, [numel(w) for w in var_list])\n",
    "    return [tf.reshape(t, var_shape(w)) for t, w in zip(splits, var_list)]\n",
    "\n",
    "\n",
    "def var_shape(tensor):\n",
    "    \"\"\"\n",
    "    get TensorFlow Tensor shape\n",
    "    :param tensor: (TensorFlow Tensor) the input tensor\n",
    "    :return: ([int]) the shape\n",
    "    \"\"\"\n",
    "    out = tensor.get_shape().as_list()\n",
    "    assert all(isinstance(a, int) for a in out), \\\n",
    "        \"shape function assumes that shape is fully known\"\n",
    "    return out\n",
    "\n",
    "\n",
    "def numel(tensor):\n",
    "    \"\"\"\n",
    "    get TensorFlow Tensor's number of elements\n",
    "    :param tensor: (TensorFlow Tensor) the input tensor\n",
    "    :return: (int) the number of elements\n",
    "    \"\"\"\n",
    "    return int(np.prod(var_shape(tensor)))\n",
    "\n",
    "\n",
    "# loss computation\n",
    "def compute_mse(train_model, x, training=True):\n",
    "    x_logit = train_model(x, training=training)\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    loss = loss_fn(x, x_logit)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd796d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TADAM\n",
    "@tf.function\n",
    "def train_step(model, tr_opt, x, lr, beta1, beta2, gamma, ls_h, ls, pr, dt, m_h, m, s, v, t, total_steps, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Executes one training step and returns the loss.\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_mse(model,x, True)\n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    g_flat = flatgrad(gradient)\n",
    "\n",
    "    # bias correction\n",
    "    bp1 = tf.pow(beta1, t)\n",
    "    bp2 = tf.pow(beta2, t)\n",
    "    bc1 = 1.0 - bp1\n",
    "    bc2 = 1.0 - bp2\n",
    "\n",
    "    # compute delta\n",
    "    if t>1:\n",
    "        rho = (ls_h - loss) / tf.maximum(pr, eps)\n",
    "    else:\n",
    "        rho = 0.5\n",
    "    dt_min = tf.pow(1.- gamma, (t-1) / total_steps)\n",
    "    dt_max = 1. + tf.pow(gamma, (t-1) / total_steps)\n",
    "    f1 = lambda: dt_min\n",
    "    f2 = lambda: dt_max\n",
    "    f3 = lambda: 1.0\n",
    "    r = tf.case([(tf.less(rho, gamma), f1), (tf.greater(rho, 1. - gamma), f2)], default=f3, exclusive=True)\n",
    "    dt = tf.minimum(tf.maximum(r * dt, dt_min), dt_max) \n",
    "\n",
    "    # moving varience\n",
    "    dv = tf.square(g_flat - m_h) * (beta2 - bp2) / bc2 \n",
    "    v = beta2 * v + (1.0 - beta2) * dv\n",
    "    v_h = v / bc2\n",
    "\n",
    "    # first moment\n",
    "    m = beta1 * m + (1.0 - beta1) * g_flat\n",
    "    m_h = m / bc1\n",
    "\n",
    "    # second moment\n",
    "    s = beta2 * s + (1.0 - beta2) * tf.square(g_flat)\n",
    "    s_h = s / bc2\n",
    "\n",
    "    # fisher vector\n",
    "    f_h = (1.0 + tf.reduce_sum(tf.square(m_h) / (v_h + eps))) * v_h\n",
    "\n",
    "    # apply trust region\n",
    "    u_h = tf.maximum(dt * f_h, tf.sqrt(s_h))\n",
    "    g_h = m_h * dt / (u_h + eps)\n",
    "\n",
    "    # update\n",
    "    g_update = flat_to_grad_list(g_h, model.trainable_variables)\n",
    "    grads_and_vars = [(grad, var) for grad, var in zip(g_update, model.trainable_variables)]\n",
    "    tr_opt.apply_gradients(grads_and_vars)\n",
    "\n",
    "    # moving avg of loss\n",
    "    ls = beta1 * ls + (1.0 - beta1) * loss\n",
    "    ls_h = ls / bc1\n",
    "\n",
    "    # predict reduction\n",
    "    pr1 = tf.reduce_sum(m_h * g_h) \n",
    "    pr2 = tf.square(pr1) + tf.reduce_sum(v_h * tf.square(g_h))\n",
    "    pr = (pr1 - 0.5 * pr2) * lr\n",
    "\n",
    "    return ls_h, ls, loss, pr, dt, m_h, m, s, v, t + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5925c4d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def training(data_name, in_shape, filters, code_dim, batch_size=128, epochs=1, \n",
    "             init_lr=1e-3, beta1=0.9, beta2=.0999, gamma=0.25, eps=1e-8, seed=0):\n",
    "    \n",
    "    print('DATA: {}, BATCH: {}, EPOCH: {}'\n",
    "          .format(data_name, batch_size, epochs))\n",
    "    print('INIT_LR: {:.0e}, BETA1: {:.4f}, BETA2: {:.4f}, GAMMA: {:.4f}'\n",
    "          .format(init_lr, beta1, beta2, gamma))\n",
    "    \n",
    "    # fix seed\n",
    "    tf.random.set_seed(seed)  # Tensorflow\n",
    "    np.random.seed(seed)  # numpy\n",
    "    random.seed(seed)  # Python\n",
    "     \n",
    "    # set model\n",
    "    model = CAE(in_shape, filters, code_dim).model\n",
    "    model.summary()\n",
    "    \n",
    "    # load data\n",
    "    train_dataset, test_dataset, train_size = load_data(data_name, batch_size)\n",
    "    steps_per_epoch = int(train_size / batch_size)\n",
    "    total_steps = int(steps_per_epoch * epochs)\n",
    "    \n",
    "    # optimizer\n",
    "    train_opt = tf.keras.optimizers.SGD(learning_rate=init_lr)\n",
    "    \n",
    "    # initial parameters\n",
    "    ls_h = 0.0\n",
    "    ls = 0.0\n",
    "    pr = 0.0\n",
    "    m_h = 0.0\n",
    "    m = 0.0\n",
    "    s = 0.0\n",
    "    v = eps\n",
    "    dt = 1.0\n",
    "    t = 1.0\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(1, epochs + 1):        \n",
    "        tmloss = tf.keras.metrics.Mean()\n",
    "        start_time = time.time()\n",
    "        for train_x in train_dataset:\n",
    "            ls_h, ls, loss, pr, dt, m_h, m, s, v, t = train_step(model, train_opt, train_x,\n",
    "                init_lr, beta1, beta2, gamma, ls_h, ls, pr, dt, m_h, m, s, v, t, total_steps)\n",
    "            tmloss(loss)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "        tloss = tmloss.result()\n",
    "\n",
    "        vmloss = tf.keras.metrics.Mean()\n",
    "        for test_x in test_dataset:\n",
    "            loss = compute_mse(model, test_x, False)\n",
    "            vmloss(loss) \n",
    "        vloss = vmloss.result()\n",
    "        \n",
    "        print('Epoch: {}, loss_t: {:.4e}, loss_v: {:.4e}, dt: {:.2f}, time: {:.2f}'\n",
    "              .format(epoch, tloss, vloss, dt, train_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f48ffa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: MNIST, BATCH: 128, EPOCH: 100\n",
      "INIT_LR: 1e-03, BETA1: 0.9000, BETA2: 0.9990, GAMMA: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 09:43:45.415647: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-24 09:43:46.155092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10410 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 16)        160       \n",
      "                                                                 \n",
      " tf.nn.silu (TFOpLambda)     (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 32)          4640      \n",
      "                                                                 \n",
      " tf.nn.silu_1 (TFOpLambda)   (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " tf.nn.silu_2 (TFOpLambda)   (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                16400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              17408     \n",
      "                                                                 \n",
      " tf.nn.silu_3 (TFOpLambda)   (None, 1024)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 32)         18464     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " tf.nn.silu_4 (TFOpLambda)   (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 16)       4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " tf.nn.silu_5 (TFOpLambda)   (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 1)        145       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,337\n",
      "Trainable params: 80,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },

    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss_t: 3.0891e-02, loss_v: 8.6022e-03, dt: 1.98, time: 8.63\n",
      "Epoch: 2, loss_t: 7.5140e-03, loss_v: 6.5878e-03, dt: 1.97, time: 4.13\n",
      "Epoch: 3, loss_t: 6.2882e-03, loss_v: 5.8424e-03, dt: 1.94, time: 4.11\n",
      "Epoch: 4, loss_t: 5.7518e-03, loss_v: 5.5353e-03, dt: 1.95, time: 4.20\n",
      "Epoch: 5, loss_t: 5.4284e-03, loss_v: 5.2315e-03, dt: 1.93, time: 4.22\n",
      "Epoch: 6, loss_t: 5.1980e-03, loss_v: 5.1990e-03, dt: 1.85, time: 4.07\n",
      "Epoch: 7, loss_t: 5.0339e-03, loss_v: 4.9703e-03, dt: 1.83, time: 4.27\n",
      "Epoch: 8, loss_t: 4.9003e-03, loss_v: 4.8134e-03, dt: 1.85, time: 4.08\n",
      "Epoch: 9, loss_t: 4.7933e-03, loss_v: 4.7303e-03, dt: 1.79, time: 4.09\n",
      "Epoch: 10, loss_t: 4.7016e-03, loss_v: 4.6963e-03, dt: 1.87, time: 4.04\n",
      "Epoch: 11, loss_t: 4.6278e-03, loss_v: 4.6031e-03, dt: 1.86, time: 4.12\n",
      "Epoch: 12, loss_t: 4.5490e-03, loss_v: 4.5586e-03, dt: 1.66, time: 4.09\n",
      "Epoch: 13, loss_t: 4.4901e-03, loss_v: 4.5198e-03, dt: 1.83, time: 4.14\n",
      "Epoch: 14, loss_t: 4.4351e-03, loss_v: 4.4338e-03, dt: 1.82, time: 4.15\n",
      "Epoch: 15, loss_t: 4.3836e-03, loss_v: 4.4440e-03, dt: 1.66, time: 4.09\n",
      "Epoch: 16, loss_t: 4.3429e-03, loss_v: 4.3949e-03, dt: 1.80, time: 4.11\n",
      "Epoch: 17, loss_t: 4.2992e-03, loss_v: 4.4170e-03, dt: 1.70, time: 4.16\n",
      "Epoch: 18, loss_t: 4.2638e-03, loss_v: 4.3156e-03, dt: 1.69, time: 4.13\n",
      "Epoch: 19, loss_t: 4.2323e-03, loss_v: 4.2640e-03, dt: 1.58, time: 4.14\n",
      "Epoch: 20, loss_t: 4.1959e-03, loss_v: 4.2523e-03, dt: 1.40, time: 4.19\n",
      "Epoch: 21, loss_t: 4.1632e-03, loss_v: 4.2125e-03, dt: 1.64, time: 4.11\n",
      "Epoch: 22, loss_t: 4.1337e-03, loss_v: 4.2107e-03, dt: 1.63, time: 4.17\n",
      "Epoch: 23, loss_t: 4.1066e-03, loss_v: 4.1979e-03, dt: 1.62, time: 4.11\n",
      "Epoch: 24, loss_t: 4.0869e-03, loss_v: 4.1928e-03, dt: 1.72, time: 4.10\n",
      "Epoch: 25, loss_t: 4.0714e-03, loss_v: 4.1525e-03, dt: 1.59, time: 4.11\n",
      "Epoch: 26, loss_t: 4.0370e-03, loss_v: 4.1142e-03, dt: 1.70, time: 4.06\n",
      "Epoch: 27, loss_t: 4.0193e-03, loss_v: 4.0987e-03, dt: 1.24, time: 4.14\n",
      "Epoch: 28, loss_t: 3.9952e-03, loss_v: 4.0875e-03, dt: 1.55, time: 4.14\n",
      "Epoch: 29, loss_t: 3.9851e-03, loss_v: 4.0595e-03, dt: 1.67, time: 4.18\n",
      "Epoch: 30, loss_t: 3.9588e-03, loss_v: 4.0449e-03, dt: 1.28, time: 4.11\n",
      "Epoch: 31, loss_t: 3.9451e-03, loss_v: 4.0456e-03, dt: 1.15, time: 4.09\n",
      "Epoch: 32, loss_t: 3.9352e-03, loss_v: 4.0923e-03, dt: 1.50, time: 4.14\n",
      "Epoch: 33, loss_t: 3.9105e-03, loss_v: 4.0595e-03, dt: 1.63, time: 4.04\n",
      "Epoch: 34, loss_t: 3.8991e-03, loss_v: 4.0238e-03, dt: 1.47, time: 4.09\n",
      "Epoch: 35, loss_t: 3.8884e-03, loss_v: 4.0208e-03, dt: 1.61, time: 4.08\n",
      "Epoch: 36, loss_t: 3.8761e-03, loss_v: 4.0385e-03, dt: 1.45, time: 4.12\n",
      "Epoch: 37, loss_t: 3.8644e-03, loss_v: 3.9770e-03, dt: 1.44, time: 4.16\n",
      "Epoch: 38, loss_t: 3.8601e-03, loss_v: 3.9467e-03, dt: 1.59, time: 4.14\n",
      "Epoch: 39, loss_t: 3.8406e-03, loss_v: 4.0384e-03, dt: 1.58, time: 4.11\n",
      "Epoch: 40, loss_t: 3.8313e-03, loss_v: 3.9446e-03, dt: 1.57, time: 4.17\n",
      "Epoch: 41, loss_t: 3.8238e-03, loss_v: 3.9956e-03, dt: 1.57, time: 4.13\n",
      "Epoch: 42, loss_t: 3.8114e-03, loss_v: 3.9655e-03, dt: 1.56, time: 4.19\n",
      "Epoch: 43, loss_t: 3.7993e-03, loss_v: 3.9396e-03, dt: 1.55, time: 4.23\n",
      "Epoch: 44, loss_t: 3.7926e-03, loss_v: 3.9368e-03, dt: 1.54, time: 4.17\n",
      "Epoch: 45, loss_t: 3.7764e-03, loss_v: 3.9199e-03, dt: 1.54, time: 4.04\n",
      "Epoch: 46, loss_t: 3.7745e-03, loss_v: 3.8856e-03, dt: 0.90, time: 4.20\n",
      "Epoch: 47, loss_t: 3.7734e-03, loss_v: 3.8817e-03, dt: 1.36, time: 4.13\n",
      "Epoch: 48, loss_t: 3.7541e-03, loss_v: 3.9344e-03, dt: 1.32, time: 4.16\n",
      "Epoch: 49, loss_t: 3.7424e-03, loss_v: 3.9136e-03, dt: 1.51, time: 4.21\n",
      "Epoch: 50, loss_t: 3.7334e-03, loss_v: 3.9043e-03, dt: 1.50, time: 4.22\n",
      "Epoch: 51, loss_t: 3.7392e-03, loss_v: 3.9571e-03, dt: 1.49, time: 4.14\n",
      "Epoch: 52, loss_t: 3.7361e-03, loss_v: 3.8794e-03, dt: 1.10, time: 4.17\n",
      "Epoch: 53, loss_t: 3.7128e-03, loss_v: 3.8844e-03, dt: 1.02, time: 4.15\n",
      "Epoch: 54, loss_t: 3.7167e-03, loss_v: 3.8549e-03, dt: 1.26, time: 4.13\n",
      "Epoch: 55, loss_t: 3.7068e-03, loss_v: 3.8894e-03, dt: 1.47, time: 4.12\n",
      "Epoch: 56, loss_t: 3.7015e-03, loss_v: 3.8290e-03, dt: 1.06, time: 4.08\n",
      "Epoch: 57, loss_t: 3.6947e-03, loss_v: 3.8399e-03, dt: 1.05, time: 4.17\n",
      "Epoch: 58, loss_t: 3.6871e-03, loss_v: 3.9421e-03, dt: 1.45, time: 4.15\n",
      "Epoch: 59, loss_t: 3.6826e-03, loss_v: 3.8332e-03, dt: 1.22, time: 4.09\n",
      "Epoch: 60, loss_t: 3.6769e-03, loss_v: 3.8294e-03, dt: 1.21, time: 4.05\n",
      "Epoch: 61, loss_t: 3.6767e-03, loss_v: 3.8141e-03, dt: 0.84, time: 4.11\n",
      "Epoch: 62, loss_t: 3.6646e-03, loss_v: 3.8336e-03, dt: 1.42, time: 4.10\n",
      "Epoch: 63, loss_t: 3.6554e-03, loss_v: 3.8281e-03, dt: 1.42, time: 4.17\n",
      "Epoch: 64, loss_t: 3.6567e-03, loss_v: 3.8070e-03, dt: 1.17, time: 4.11\n",
      "Epoch: 65, loss_t: 3.6615e-03, loss_v: 3.8179e-03, dt: 0.83, time: 4.07\n",
      "Epoch: 66, loss_t: 3.6346e-03, loss_v: 3.8203e-03, dt: 1.40, time: 4.17\n",
      "Epoch: 67, loss_t: 3.6390e-03, loss_v: 3.8484e-03, dt: 1.15, time: 4.21\n",
      "Epoch: 68, loss_t: 3.6359e-03, loss_v: 3.8279e-03, dt: 1.39, time: 4.09\n",
      "Epoch: 69, loss_t: 3.6270e-03, loss_v: 3.7897e-03, dt: 0.82, time: 4.19\n",
      "Epoch: 70, loss_t: 3.6229e-03, loss_v: 3.8501e-03, dt: 1.38, time: 4.15\n",
      "Epoch: 71, loss_t: 3.6673e-03, loss_v: 3.8003e-03, dt: 0.91, time: 4.08\n",
      "Epoch: 72, loss_t: 3.6057e-03, loss_v: 3.8142e-03, dt: 1.11, time: 4.10\n",
      "Epoch: 73, loss_t: 3.6053e-03, loss_v: 3.7649e-03, dt: 1.22, time: 4.18\n",
      "Epoch: 74, loss_t: 3.6043e-03, loss_v: 3.7997e-03, dt: 1.36, time: 4.09\n",
      "Epoch: 75, loss_t: 3.6032e-03, loss_v: 3.7849e-03, dt: 1.35, time: 4.15\n",
      "Epoch: 76, loss_t: 3.5984e-03, loss_v: 3.7616e-03, dt: 0.87, time: 4.18\n",
      "Epoch: 77, loss_t: 3.5935e-03, loss_v: 3.7652e-03, dt: 1.08, time: 4.16\n",
      "Epoch: 78, loss_t: 3.5909e-03, loss_v: 3.8027e-03, dt: 0.91, time: 4.18\n",
      "Epoch: 79, loss_t: 3.5874e-03, loss_v: 3.7707e-03, dt: 1.06, time: 4.15\n",
      "Epoch: 80, loss_t: 3.5875e-03, loss_v: 3.7623e-03, dt: 1.11, time: 4.14\n",
      "Epoch: 81, loss_t: 3.5775e-03, loss_v: 3.7975e-03, dt: 1.05, time: 4.08\n",
      "Epoch: 82, loss_t: 3.5724e-03, loss_v: 3.7549e-03, dt: 0.79, time: 4.12\n",
      "Epoch: 83, loss_t: 3.5804e-03, loss_v: 3.7635e-03, dt: 1.32, time: 4.11\n",
      "Epoch: 84, loss_t: 3.5623e-03, loss_v: 3.7516e-03, dt: 0.81, time: 4.16\n",
      "Epoch: 85, loss_t: 3.5631e-03, loss_v: 3.7537e-03, dt: 1.31, time: 4.13\n",
      "Epoch: 86, loss_t: 3.5626e-03, loss_v: 3.7530e-03, dt: 1.02, time: 4.20\n",
      "Epoch: 87, loss_t: 3.5620e-03, loss_v: 3.7912e-03, dt: 1.01, time: 4.12\n",
      "Epoch: 88, loss_t: 3.5479e-03, loss_v: 3.7267e-03, dt: 0.79, time: 4.11\n",
      "Epoch: 89, loss_t: 3.5565e-03, loss_v: 3.7559e-03, dt: 1.29, time: 4.23\n",
      "Epoch: 90, loss_t: 3.5471e-03, loss_v: 3.7721e-03, dt: 1.29, time: 4.21\n",
      "Epoch: 91, loss_t: 3.5390e-03, loss_v: 3.7644e-03, dt: 0.77, time: 4.15\n",
      "Epoch: 92, loss_t: 3.5419e-03, loss_v: 3.7589e-03, dt: 1.28, time: 4.19\n",
      "Epoch: 93, loss_t: 3.5369e-03, loss_v: 3.7107e-03, dt: 0.76, time: 4.10\n",
      "Epoch: 94, loss_t: 3.5300e-03, loss_v: 3.7269e-03, dt: 0.76, time: 4.11\n",
      "Epoch: 95, loss_t: 3.5312e-03, loss_v: 3.7362e-03, dt: 0.76, time: 4.15\n",
      "Epoch: 96, loss_t: 3.5252e-03, loss_v: 3.7334e-03, dt: 0.76, time: 4.15\n",
      "Epoch: 97, loss_t: 3.5262e-03, loss_v: 3.6973e-03, dt: 0.76, time: 4.12\n",
      "Epoch: 98, loss_t: 3.5251e-03, loss_v: 3.7307e-03, dt: 1.26, time: 4.06\n",
      "Epoch: 99, loss_t: 3.5193e-03, loss_v: 3.6894e-03, dt: 0.75, time: 4.20\n",
      "Epoch: 100, loss_t: 3.5166e-03, loss_v: 3.7259e-03, dt: 1.17, time: 4.15\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "datas = ['MNIST', 'Fashion-MNIST', 'CIFAR-10']\n",
    "in_shape = (32, 32, 1)\n",
    "filters = [16, 32, 64]\n",
    "code_dim = 16\n",
    "\n",
    "training(datas[0], in_shape, filters, code_dim, batch_size=128, epochs=100, \n",
    "         init_lr=1e-3, beta1=0.9, beta2=0.999, gamma=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2ce0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
