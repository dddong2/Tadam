{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5598ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class Tadam():\n",
    "    def __init__(self, model, total_steps, lr=1e-3, beta1=0.9, beta2=0.999, gamma=0.25, eps=1e-8, name='TADAM',**kwargs):   \n",
    "        self.model = model\n",
    "        self.total_steps = total_steps\n",
    "        self.lr = lr\n",
    "        self.bt1 = beta1\n",
    "        self.bt2 = beta2\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.shape = self.flatgrad(self.model.trainable_variables).get_shape()\n",
    "        self.zero_init = tf.constant(0.0, shape=self.shape)\n",
    "        \n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.m_h = K.variable(self.zero_init, name='m_h')\n",
    "            self.m = K.variable(self.zero_init, name='m')\n",
    "            self.s = K.variable(self.zero_init, name='s')\n",
    "            self.v = K.variable(self.zero_init + eps, name='v')\n",
    "            self.bp1 = K.variable(beta1, name='bp1')\n",
    "            self.bp2 = K.variable(beta2, name='bp2')\n",
    "            self.ls_h = K.variable(0.0, name='ls_h')\n",
    "            self.ls = K.variable(0.0, name='ls')\n",
    "            self.pr = K.variable(0.0, name='pr')\n",
    "            self.dt = K.variable(1.0, name='dt')\n",
    "            self.t = K.variable(1.0, name='t')\n",
    "        \n",
    "    def apply_grad(self, loss, gradient):\n",
    "        # gradient\n",
    "        g_flat = self.flatgrad(gradient)\n",
    "        \n",
    "        # delta\n",
    "        d1 = lambda: 1.0\n",
    "        d2 = lambda: self.compute_delta(loss, self.dt)\n",
    "        self.dt.assign(tf.case([(tf.less(self.t, 1.1), d1)], default=d2, exclusive=True))\n",
    "        \n",
    "        # bias correction\n",
    "        bc1 = 1.0 - self.bp1\n",
    "        bc2 = 1.0 - self.bp2\n",
    "        \n",
    "        # moving varience\n",
    "        dv = tf.square(g_flat - self.m_h) * (self.bt2 - self.bp2) / bc2 \n",
    "        self.v.assign(self.bt2 * self.v + (1.0 - self.bt2) * dv)\n",
    "        v_h = self.v / bc2\n",
    "        \n",
    "        # first moment\n",
    "        self.m.assign(self.bt1 * self.m + (1.0 - self.bt1) * g_flat)\n",
    "        self.m_h.assign(self.m / bc1)\n",
    "        \n",
    "        # second moment\n",
    "        self.s.assign(self.bt2 * self.s + (1.0 - self.bt2) * tf.square(g_flat))\n",
    "        s_h = self.s / bc2\n",
    "        \n",
    "        # fisher vector\n",
    "        f_h = (1.0 + tf.reduce_sum(tf.square(self.m_h) / (v_h + self.eps))) * v_h\n",
    "        \n",
    "        # apply trust region\n",
    "        u_h = tf.maximum(self.dt * f_h, tf.sqrt(s_h))\n",
    "        g_h = self.m_h * self.dt / (u_h + self.eps)\n",
    "        \n",
    "        # update\n",
    "        g_update = self.flat_to_grad_list(g_h, self.model.trainable_variables)\n",
    "        p_update = [var.assign(var - self.lr*grad) for grad, var in zip(g_update, self.model.trainable_variables)]\n",
    "        \n",
    "        # moving avg of loss\n",
    "        self.ls.assign(self.bt1 * self.ls + (1.0 - self.bt1) * loss)\n",
    "        self.ls_h.assign(self.ls / bc1)\n",
    "        \n",
    "        # predict reduction\n",
    "        pr1 = tf.reduce_sum(self.m_h * g_h) \n",
    "        pr2 = tf.square(pr1) + tf.reduce_sum(v_h * tf.square(g_h))\n",
    "        self.pr.assign((pr1 - 0.5 * pr2) * self.lr)\n",
    "        \n",
    "        # beta update\n",
    "        self.bp1.assign(self.bp1*self.bt1)\n",
    "        self.bp2.assign(self.bp2*self.bt2)\n",
    "        self.t.assign_add(1.0)\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def compute_delta(self, loss, dt):\n",
    "        rho = self.compute_rho(loss)\n",
    "        dt_min = tf.pow(1.0 - self.gamma, (self.t - 1.0) / self.total_steps)\n",
    "        dt_max = 1.0 + tf.pow(self.gamma, (self.t - 1.0) / self.total_steps)\n",
    "        r1 = lambda: dt_min\n",
    "        r2 = lambda: dt_max\n",
    "        r3 = lambda: 1.0\n",
    "        r = tf.case([(tf.less(rho, self.gamma), r1), (tf.greater(rho, 1.0 - self.gamma), r2)], default=r3, exclusive=True)\n",
    "        dt = tf.minimum(tf.maximum(r * dt, dt_min), dt_max)\n",
    "        return dt\n",
    "    \n",
    "    def compute_rho(self, loss):\n",
    "        return (self.ls_h - loss) / tf.maximum(self.pr, self.eps)\n",
    "        \n",
    "    def flatgrad(self, grad_list):\n",
    "        \"\"\"\n",
    "        flattens gradients.\n",
    "        :param grad_list: ([TensorFlow Tensor]) the gradients\n",
    "        :return: ([TensorFlow Tensor]) flattened gradient\n",
    "        \"\"\"\n",
    "        return tf.concat(axis=0, values=[tf.reshape(grad, [-1]) for grad in grad_list])\n",
    "\n",
    "    def flat_to_grad_list(self, flat, var_list):\n",
    "        \"\"\"\n",
    "        converts flats to the form of var_list.\n",
    "        :param flat:\n",
    "        :param var_list:\n",
    "        :return: [(Tensorflow Tensor)]\n",
    "        \"\"\"\n",
    "        splits = tf.split(flat, [self.numel(w) for w in var_list])\n",
    "        return [tf.reshape(t, self.var_shape(w)) for t, w in zip(splits, var_list)]\n",
    "\n",
    "    def var_shape(self, tensor):\n",
    "        \"\"\"\n",
    "        get TensorFlow Tensor shape\n",
    "        :param tensor: (TensorFlow Tensor) the input tensor\n",
    "        :return: ([int]) the shape\n",
    "        \"\"\"\n",
    "        out = tensor.get_shape().as_list()\n",
    "        assert all(isinstance(a, int) for a in out), \\\n",
    "            \"shape function assumes that shape is fully known\"\n",
    "        return out\n",
    "\n",
    "    def numel(self, tensor):\n",
    "        \"\"\"\n",
    "        get TensorFlow Tensor's number of elements\n",
    "        :param tensor: (TensorFlow Tensor) the input tensor\n",
    "        :return: (int) the number of elements\n",
    "        \"\"\"\n",
    "        return int(np.prod(self.var_shape(tensor)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148a91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class CAE(tf.keras.Model):\n",
    "    def __init__(self, in_shape, filters, code_dim):\n",
    "        super(CAE, self).__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.filters = filters\n",
    "        self.code_dim = code_dim\n",
    "        \n",
    "        # input\n",
    "        self.inputs = tf.keras.layers.Input(shape=self.in_shape)\n",
    "\n",
    "        # encoder\n",
    "        self.enc01 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[0], kernel_size=3, strides=2, padding='same')(self.inputs)\n",
    "        self.enc01 = tf.keras.activations.swish(self.enc01)\n",
    "        \n",
    "        self.enc02 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[1], kernel_size=3, strides=2, padding='same')(self.enc01)\n",
    "        self.enc02 = tf.keras.activations.swish(self.enc02)\n",
    "        \n",
    "        self.enc03 = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters[2], kernel_size=3, strides=2, padding='same')(self.enc02)\n",
    "        self.enc03 = tf.keras.activations.swish(self.enc03)\n",
    "        self.enc03_flat = tf.keras.layers.Flatten()(self.enc03)\n",
    "        \n",
    "        # code\n",
    "        self.code = tf.keras.layers.Dense(self.code_dim)(self.enc03_flat)\n",
    "        \n",
    "        # decoder\n",
    "        self.dec03 = tf.keras.layers.Dense(self.enc03_flat.shape[-1])(self.code)\n",
    "        self.dec03 = tf.keras.activations.swish(self.dec03)\n",
    "        self.dec03 = tf.keras.layers.Reshape(target_shape=self.enc03.shape[1:])(self.dec03)\n",
    "\n",
    "        self.dec02 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.filters[1], kernel_size=3, strides=2, padding='same')(self.dec03)\n",
    "        self.dec02 = tf.keras.activations.swish(self.dec02)\n",
    "\n",
    "        self.dec01 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.filters[0], kernel_size=3, strides=2, padding='same')(self.dec02)\n",
    "        self.dec01 = tf.keras.activations.swish(self.dec01)\n",
    "        \n",
    "        # output\n",
    "        self.outputs = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=self.in_shape[2], kernel_size=3, strides=2, padding='same')(self.dec01)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=self.inputs, outputs=self.outputs, name='ConvAE')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390b9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_data(batch_size, epochs):\n",
    "    (train_ds,_), (test_ds,_) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_size = train_ds.shape[0]\n",
    "    test_size = test_ds.shape[0]\n",
    "\n",
    "    train_ds = preprocess_images(train_ds)\n",
    "    test_ds = preprocess_images(test_ds)\n",
    "\n",
    "    train_ds = (tf.data.Dataset.from_tensor_slices(train_ds)\n",
    "                     .shuffle(train_size).batch(batch_size))\n",
    "    test_ds = (tf.data.Dataset.from_tensor_slices(test_ds)\n",
    "                    .shuffle(test_size).batch(batch_size))\n",
    "    \n",
    "    steps_per_epoch = int(train_size / batch_size)\n",
    "    total_steps = int(steps_per_epoch * epochs)\n",
    "\n",
    "    return train_ds, test_ds, total_steps\n",
    "\n",
    "\n",
    "def preprocess_images(img):\n",
    "    img = (img.reshape((img.shape[0], 28, 28, 1)) / 255.).astype('float32')\n",
    "    img = tf.image.resize(img, [32,32])\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bea0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss computation\n",
    "def compute_mse(train_model, x, training=True):\n",
    "    x_logit = train_model(x, training=training)\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    loss = loss_fn(x, x_logit)\n",
    "    return loss\n",
    "\n",
    "# optimiztion\n",
    "@tf.function\n",
    "def train_step(model, opt, x):\n",
    "    \"\"\"\n",
    "    Executes one training step and returns the loss.\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_mse(model, x, True)\n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    opt.apply_grad(loss, gradient)\n",
    "    delta = opt.dt\n",
    "    \n",
    "    return loss, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5925c4d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def training(in_shape, filters, code_dim, batch_size, epochs=1, \n",
    "             init_lr=1e-3, beta1=0.9, beta2=0.999, gamma=0.25, seed=0):\n",
    "    \n",
    "    print('LOSS: {}, DATA: {},  BATCH: {}, EPOCH: {}, SEED: {}'\n",
    "          .format('MSE', 'MNIST', batch_size, epochs, seed))\n",
    "    print('INIT_LR: {:.0e}, BETA1: {:.4f}, BETA2: {:.4f}, GAMMA: {:.4f}'\n",
    "          .format(init_lr, beta1, beta2, gamma))\n",
    "    \n",
    "    # fix seed\n",
    "    tf.random.set_seed(seed)  # Tensorflow\n",
    "    np.random.seed(seed)  # numpy\n",
    "    random.seed(seed)  # Python\n",
    "    \n",
    "    # model\n",
    "    model = CAE(in_shape, filters, code_dim).model\n",
    "    model.summary()\n",
    "    \n",
    "    # data\n",
    "    train_dataset, test_dataset, total_steps = load_data(batch_size, epochs)\n",
    "\n",
    "    # optimizer\n",
    "    opt = Tadam(model, total_steps, init_lr, beta1, beta2, gamma)\n",
    "    \n",
    "    # train model\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        tmloss = tf.keras.metrics.Mean()\n",
    "        start_time = time.time()\n",
    "        for train_x in train_dataset:\n",
    "            loss, delta = train_step(model, opt, train_x)\n",
    "            tmloss(loss)\n",
    "        end_time = time.time()\n",
    "        tloss = tmloss.result()\n",
    "\n",
    "        vmloss = tf.keras.metrics.Mean()\n",
    "        for test_x in test_dataset:\n",
    "            loss = compute_mse(model, test_x, False)\n",
    "            vmloss(loss) \n",
    "        vloss = vmloss.result()\n",
    "\n",
    "        print('Epoch: {}, loss_t: {:.4e}, loss_v: {:.4e}, dt: {:.2f}, time: {:.2f}'\n",
    "              .format(epoch, tloss, vloss, delta, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f48ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: MSE,  DATA: MNIST,  BATCH: 128, EPOCH: 100, SEED: 0\n",
      "INIT_LR: 1e-03, BETA1: 0.9000, BETA2: 0.9990, GAMMA: 0.2500\n",
      "Model: \"ConvAE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 16)        160       \n",
      "                                                                 \n",
      " tf.nn.silu (TFOpLambda)     (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 32)          4640      \n",
      "                                                                 \n",
      " tf.nn.silu_1 (TFOpLambda)   (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " tf.nn.silu_2 (TFOpLambda)   (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                16400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              17408     \n",
      "                                                                 \n",
      " tf.nn.silu_3 (TFOpLambda)   (None, 1024)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 32)         18464     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " tf.nn.silu_4 (TFOpLambda)   (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 16)       4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " tf.nn.silu_5 (TFOpLambda)   (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 1)        145       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,337\n",
      "Trainable params: 80,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss_t: 3.0960e-02, loss_v: 8.5160e-03, dt: 1.98, time: 7.87\n",
      "Epoch: 2, loss_t: 7.5089e-03, loss_v: 6.6965e-03, dt: 1.97, time: 4.10\n",
      "Epoch: 3, loss_t: 6.3080e-03, loss_v: 5.8726e-03, dt: 1.93, time: 4.15\n",
      "Epoch: 4, loss_t: 5.7805e-03, loss_v: 5.6573e-03, dt: 1.88, time: 4.04\n",
      "Epoch: 5, loss_t: 5.4316e-03, loss_v: 5.2908e-03, dt: 1.93, time: 4.11\n",
      "Epoch: 6, loss_t: 5.1926e-03, loss_v: 5.0891e-03, dt: 1.92, time: 4.11\n",
      "Epoch: 7, loss_t: 5.0272e-03, loss_v: 4.9590e-03, dt: 1.87, time: 4.14\n",
      "Epoch: 8, loss_t: 4.8847e-03, loss_v: 4.8127e-03, dt: 1.77, time: 4.09\n",
      "Epoch: 9, loss_t: 4.7653e-03, loss_v: 4.7324e-03, dt: 1.83, time: 4.07\n",
      "Epoch: 10, loss_t: 4.6741e-03, loss_v: 4.6151e-03, dt: 1.77, time: 4.14\n",
      "Epoch: 11, loss_t: 4.5990e-03, loss_v: 4.5685e-03, dt: 1.74, time: 4.16\n",
      "Epoch: 12, loss_t: 4.5281e-03, loss_v: 4.5227e-03, dt: 1.78, time: 4.04\n",
      "Epoch: 13, loss_t: 4.4550e-03, loss_v: 4.4895e-03, dt: 1.83, time: 4.09\n",
      "Epoch: 14, loss_t: 4.4084e-03, loss_v: 4.4145e-03, dt: 1.75, time: 4.05\n",
      "Epoch: 15, loss_t: 4.3669e-03, loss_v: 4.3937e-03, dt: 1.59, time: 4.12\n",
      "Epoch: 16, loss_t: 4.3161e-03, loss_v: 4.3009e-03, dt: 1.80, time: 4.21\n",
      "Epoch: 17, loss_t: 4.2699e-03, loss_v: 4.3185e-03, dt: 1.70, time: 4.09\n",
      "Epoch: 18, loss_t: 4.2414e-03, loss_v: 4.2961e-03, dt: 1.60, time: 4.09\n",
      "Epoch: 19, loss_t: 4.2125e-03, loss_v: 4.2593e-03, dt: 1.77, time: 4.14\n",
      "Epoch: 20, loss_t: 4.1717e-03, loss_v: 4.2303e-03, dt: 1.76, time: 4.09\n",
      "Epoch: 21, loss_t: 4.1475e-03, loss_v: 4.2438e-03, dt: 1.55, time: 4.22\n",
      "Epoch: 22, loss_t: 4.1299e-03, loss_v: 4.2025e-03, dt: 1.53, time: 4.08\n",
      "Epoch: 23, loss_t: 4.0968e-03, loss_v: 4.2259e-03, dt: 1.73, time: 4.03\n",
      "Epoch: 24, loss_t: 4.0748e-03, loss_v: 4.1271e-03, dt: 1.60, time: 4.03\n",
      "Epoch: 25, loss_t: 4.0594e-03, loss_v: 4.1468e-03, dt: 1.48, time: 4.02\n",
      "Epoch: 26, loss_t: 4.0304e-03, loss_v: 4.1671e-03, dt: 1.70, time: 4.08\n",
      "Epoch: 27, loss_t: 4.0172e-03, loss_v: 4.0807e-03, dt: 1.34, time: 4.14\n",
      "Epoch: 28, loss_t: 4.0025e-03, loss_v: 4.0610e-03, dt: 1.55, time: 4.09\n",
      "Epoch: 29, loss_t: 3.9794e-03, loss_v: 4.1292e-03, dt: 1.67, time: 3.99\n",
      "Epoch: 30, loss_t: 3.9597e-03, loss_v: 4.0640e-03, dt: 1.66, time: 4.05\n",
      "Epoch: 31, loss_t: 3.9484e-03, loss_v: 4.0583e-03, dt: 1.65, time: 4.14\n",
      "Epoch: 32, loss_t: 3.9362e-03, loss_v: 4.0195e-03, dt: 1.36, time: 4.10\n",
      "Epoch: 33, loss_t: 3.9216e-03, loss_v: 4.0470e-03, dt: 1.63, time: 4.10\n",
      "Epoch: 34, loss_t: 3.9075e-03, loss_v: 4.0415e-03, dt: 1.62, time: 4.08\n",
      "Epoch: 35, loss_t: 3.8909e-03, loss_v: 3.9647e-03, dt: 1.61, time: 4.05\n",
      "Epoch: 36, loss_t: 3.8849e-03, loss_v: 4.0156e-03, dt: 1.18, time: 4.09\n",
      "Epoch: 37, loss_t: 3.8703e-03, loss_v: 3.9332e-03, dt: 1.60, time: 4.07\n",
      "Epoch: 38, loss_t: 3.8489e-03, loss_v: 3.9661e-03, dt: 1.42, time: 4.15\n",
      "Epoch: 39, loss_t: 3.8457e-03, loss_v: 3.9611e-03, dt: 1.58, time: 4.14\n",
      "Epoch: 40, loss_t: 3.8302e-03, loss_v: 3.9291e-03, dt: 0.89, time: 4.11\n",
      "Epoch: 41, loss_t: 3.8134e-03, loss_v: 3.9313e-03, dt: 1.57, time: 4.04\n",
      "Epoch: 42, loss_t: 3.8098e-03, loss_v: 3.9227e-03, dt: 1.56, time: 4.06\n",
      "Epoch: 43, loss_t: 3.7996e-03, loss_v: 3.9136e-03, dt: 1.37, time: 4.07\n",
      "Epoch: 44, loss_t: 3.7852e-03, loss_v: 3.9672e-03, dt: 1.36, time: 4.12\n",
      "Epoch: 45, loss_t: 3.7769e-03, loss_v: 3.9093e-03, dt: 1.54, time: 4.10\n",
      "Epoch: 46, loss_t: 3.7631e-03, loss_v: 3.9274e-03, dt: 1.34, time: 4.12\n",
      "Epoch: 47, loss_t: 3.7612e-03, loss_v: 3.8845e-03, dt: 1.52, time: 4.08\n",
      "Epoch: 48, loss_t: 3.7502e-03, loss_v: 3.8659e-03, dt: 1.32, time: 4.12\n",
      "Epoch: 49, loss_t: 3.7523e-03, loss_v: 3.8778e-03, dt: 1.14, time: 4.00\n",
      "Epoch: 50, loss_t: 3.7273e-03, loss_v: 3.8726e-03, dt: 1.50, time: 4.11\n",
      "Epoch: 51, loss_t: 3.7250e-03, loss_v: 3.8946e-03, dt: 1.49, time: 4.07\n",
      "Epoch: 52, loss_t: 3.7198e-03, loss_v: 3.8172e-03, dt: 1.10, time: 4.05\n",
      "Epoch: 53, loss_t: 3.7092e-03, loss_v: 3.8777e-03, dt: 1.27, time: 4.02\n",
      "Epoch: 54, loss_t: 3.7000e-03, loss_v: 3.8720e-03, dt: 1.47, time: 4.07\n",
      "Epoch: 55, loss_t: 3.6957e-03, loss_v: 3.8626e-03, dt: 1.47, time: 4.09\n",
      "Epoch: 56, loss_t: 3.6906e-03, loss_v: 3.8403e-03, dt: 1.24, time: 4.10\n",
      "Epoch: 57, loss_t: 3.6864e-03, loss_v: 3.8093e-03, dt: 1.23, time: 4.12\n",
      "Epoch: 58, loss_t: 3.6727e-03, loss_v: 3.8881e-03, dt: 1.45, time: 4.06\n",
      "Epoch: 59, loss_t: 3.6666e-03, loss_v: 3.7737e-03, dt: 1.22, time: 4.12\n",
      "Epoch: 60, loss_t: 3.6666e-03, loss_v: 3.8421e-03, dt: 1.02, time: 4.06\n",
      "Epoch: 61, loss_t: 3.6542e-03, loss_v: 3.8161e-03, dt: 1.43, time: 4.03\n",
      "Epoch: 62, loss_t: 3.6460e-03, loss_v: 3.8046e-03, dt: 0.84, time: 4.10\n",
      "Epoch: 63, loss_t: 3.6494e-03, loss_v: 3.8059e-03, dt: 1.42, time: 4.09\n",
      "Epoch: 64, loss_t: 3.6407e-03, loss_v: 3.7831e-03, dt: 1.17, time: 4.11\n",
      "Epoch: 65, loss_t: 3.6319e-03, loss_v: 3.8851e-03, dt: 1.41, time: 4.04\n",
      "Epoch: 66, loss_t: 3.6263e-03, loss_v: 3.7895e-03, dt: 1.11, time: 4.16\n",
      "Epoch: 67, loss_t: 3.6276e-03, loss_v: 3.7969e-03, dt: 1.39, time: 4.05\n",
      "Epoch: 68, loss_t: 3.6172e-03, loss_v: 3.8263e-03, dt: 0.94, time: 4.13\n",
      "Epoch: 69, loss_t: 3.6068e-03, loss_v: 3.7707e-03, dt: 1.29, time: 4.12\n",
      "Epoch: 70, loss_t: 3.5995e-03, loss_v: 3.7637e-03, dt: 1.38, time: 4.07\n",
      "Epoch: 71, loss_t: 3.5977e-03, loss_v: 3.7892e-03, dt: 1.25, time: 4.16\n",
      "Epoch: 72, loss_t: 3.5961e-03, loss_v: 3.7567e-03, dt: 0.81, time: 4.12\n",
      "Epoch: 73, loss_t: 3.5889e-03, loss_v: 3.7526e-03, dt: 1.10, time: 4.07\n",
      "Epoch: 74, loss_t: 3.5828e-03, loss_v: 3.7717e-03, dt: 1.36, time: 4.10\n",
      "Epoch: 75, loss_t: 3.5767e-03, loss_v: 3.7834e-03, dt: 1.29, time: 4.07\n",
      "Epoch: 76, loss_t: 3.5734e-03, loss_v: 3.7686e-03, dt: 0.80, time: 4.15\n",
      "Epoch: 77, loss_t: 3.5718e-03, loss_v: 3.7870e-03, dt: 1.34, time: 4.06\n",
      "Epoch: 78, loss_t: 3.5712e-03, loss_v: 3.7476e-03, dt: 1.07, time: 4.10\n",
      "Epoch: 79, loss_t: 3.5647e-03, loss_v: 3.7311e-03, dt: 0.85, time: 4.14\n",
      "Epoch: 80, loss_t: 3.5544e-03, loss_v: 3.7598e-03, dt: 1.11, time: 4.05\n",
      "Epoch: 81, loss_t: 3.5553e-03, loss_v: 3.7414e-03, dt: 1.32, time: 4.11\n",
      "Epoch: 82, loss_t: 3.5484e-03, loss_v: 3.7321e-03, dt: 0.79, time: 4.05\n",
      "Epoch: 83, loss_t: 3.5461e-03, loss_v: 3.7119e-03, dt: 1.32, time: 4.09\n",
      "Epoch: 84, loss_t: 3.5388e-03, loss_v: 3.7451e-03, dt: 1.03, time: 4.06\n",
      "Epoch: 85, loss_t: 3.5408e-03, loss_v: 3.7395e-03, dt: 1.31, time: 4.10\n",
      "Epoch: 86, loss_t: 3.5446e-03, loss_v: 3.7232e-03, dt: 1.30, time: 4.19\n",
      "Epoch: 87, loss_t: 3.5340e-03, loss_v: 3.6999e-03, dt: 0.79, time: 4.08\n",
      "Epoch: 88, loss_t: 3.5179e-03, loss_v: 3.7308e-03, dt: 1.29, time: 4.06\n",
      "Epoch: 89, loss_t: 3.5228e-03, loss_v: 3.7176e-03, dt: 1.00, time: 4.06\n",
      "Epoch: 90, loss_t: 3.5156e-03, loss_v: 3.7209e-03, dt: 1.28, time: 4.14\n",
      "Epoch: 91, loss_t: 3.5176e-03, loss_v: 3.6844e-03, dt: 0.77, time: 4.08\n",
      "Epoch: 92, loss_t: 3.5089e-03, loss_v: 3.7872e-03, dt: 1.28, time: 4.05\n",
      "Epoch: 93, loss_t: 3.5105e-03, loss_v: 3.6988e-03, dt: 0.76, time: 4.06\n",
      "Epoch: 94, loss_t: 3.5027e-03, loss_v: 3.7346e-03, dt: 1.23, time: 4.10\n",
      "Epoch: 95, loss_t: 3.5023e-03, loss_v: 3.7234e-03, dt: 0.93, time: 4.13\n",
      "Epoch: 96, loss_t: 3.4925e-03, loss_v: 3.7435e-03, dt: 1.21, time: 4.15\n",
      "Epoch: 97, loss_t: 3.5006e-03, loss_v: 3.6899e-03, dt: 0.91, time: 4.08\n",
      "Epoch: 98, loss_t: 3.4914e-03, loss_v: 3.6538e-03, dt: 0.75, time: 4.14\n",
      "Epoch: 99, loss_t: 3.4888e-03, loss_v: 3.6842e-03, dt: 1.18, time: 4.14\n",
      "Epoch: 100, loss_t: 3.4867e-03, loss_v: 3.6857e-03, dt: 0.94, time: 4.08\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "in_shape = (32, 32, 1)\n",
    "filters = [16, 32, 64]\n",
    "code_dim = 16\n",
    "\n",
    "training(in_shape, filters, code_dim, batch_size=128, epochs=100, \n",
    "         init_lr=1e-3, beta1=0.9, beta2=0.999, gamma=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2ce0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
